{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the problem parameters\n",
    "MAX_OFFER = 10  # Maximum possible offer\n",
    "MAINTENANCE_COST = 1  # Maintenance cost per day\n",
    "OFFER_PROBABILITIES = [0.0, 0.1, 0.1, 0.1, 0.1, 0.05, 0.05, 0.05, 0.05, 0.3, 0.1]  # Probability of receiving each offer\n",
    "NUM_OFFERS = len(OFFER_PROBABILITIES)  # Number of distinct offers\n",
    "T = 10 # Time horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_transition_matrix(offer_probabilities: list[float], max_offer: int) -> np.ndarray:\n",
    "    transition_probability_matrix = np.zeros((max_offer + 1, max_offer + 1))\n",
    "    for i in range(max_offer + 1):\n",
    "        for j in range(max_offer + 1):\n",
    "            if j < i:\n",
    "                transition_probability_matrix[i, j] = 0\n",
    "            elif j == i:\n",
    "                transition_probability_matrix[i, j] = sum(offer_probabilities[:min(j + 1, NUM_OFFERS)])\n",
    "            else:\n",
    "                if j < NUM_OFFERS:\n",
    "                    transition_probability_matrix[i, j] = offer_probabilities[j]\n",
    "                else:\n",
    "                    transition_probability_matrix[i, j] = 0\n",
    "    return transition_probability_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finite_horizon_value_iteration():\n",
    "    # Initialize value function for time T\n",
    "    V = np.zeros((T + 1, MAX_OFFER + 1))\n",
    "    V[T] = [i for i in range(MAX_OFFER+1)] # Terminal rewards\n",
    "    # print(V[T])\n",
    "    \n",
    "    # Initialize optimal policy\n",
    "    pi_star = np.zeros((T, MAX_OFFER + 1), dtype=int)\n",
    "    \n",
    "    P = prob_transition_matrix(OFFER_PROBABILITIES, MAX_OFFER)\n",
    "    \n",
    "    # Backward induction\n",
    "    for t in range(T - 1, -1, -1):\n",
    "        for state in range(MAX_OFFER + 1):\n",
    "            # Value of stopping (accepting current offer)\n",
    "            stop_value = -V[T][state]\n",
    "            \n",
    "            # Value of continuing\n",
    "            continue_value = MAINTENANCE_COST + np.sum(P[state] * V[t+1])\n",
    "            \n",
    "            # Update value function\n",
    "            V[t][state] = min(stop_value, continue_value)\n",
    "            \n",
    "            if continue_value < stop_value:\n",
    "                pi_star[t][state] = 0 \n",
    "            else:\n",
    "                pi_star[t][state] = 1\n",
    "    \n",
    "    return V, pi_star\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Function at t=0 [ -6.89720317  -6.89720317  -6.89720317  -6.89720368  -6.89722336\n",
      "  -6.89748551  -6.89824219  -7.          -8.          -9.\n",
      " -10.        ]\n",
      "Optimal Policy at t=0 [0 0 0 0 0 0 0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "V, pi_star = finite_horizon_value_iteration()\n",
    "print(f\"Value Function at t={0}\", V[0])\n",
    "print(f\"Optimal Policy at t={0}\", pi_star[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Function at t=0 [ -6.89720317  -6.89720317  -6.89720317  -6.89720368  -6.89722336\n",
      "  -6.89748551  -6.89824219  -7.          -8.          -9.\n",
      " -10.        ]\n",
      "Optimal Policy at t=0 [0 0 0 0 0 0 0 1 1 1 1]\n",
      "\n",
      "Value Function at t=1 [ -6.89407932  -6.89407932  -6.89407933  -6.89408189  -6.8941475\n",
      "  -6.89480286  -6.89648438  -7.          -8.          -9.\n",
      " -10.        ]\n",
      "Optimal Policy at t=1 [0 0 0 0 0 0 0 1 1 1 1]\n",
      "\n",
      "Value Function at t=2 [ -6.88736206  -6.88736206  -6.88736216  -6.88737496  -6.88759366\n",
      "  -6.88923206  -6.89296875  -7.          -8.          -9.\n",
      " -10.        ]\n",
      "Optimal Policy at t=2 [0 0 0 0 0 0 0 1 1 1 1]\n",
      "\n",
      "Value Function at t=3 [ -6.87274373  -6.87274373  -6.87274473  -6.87280873  -6.87353773\n",
      "  -6.87763373  -6.8859375   -7.          -8.          -9.\n",
      " -10.        ]\n",
      "Optimal Policy at t=3 [0 0 0 0 0 0 0 1 1 1 1]\n",
      "\n",
      "Value Function at t=4 [ -6.84042219  -6.84042219  -6.84043219  -6.84075219  -6.84318219\n",
      "  -6.85342219  -6.871875    -7.          -8.          -9.\n",
      " -10.        ]\n",
      "Optimal Policy at t=4 [0 0 0 0 0 0 0 1 1 1 1]\n",
      "\n",
      "Value Function at t=5 [ -6.76734375  -6.76734375  -6.76744375  -6.76904375  -6.77714375\n",
      "  -6.80274375  -6.84375     -7.          -8.          -9.\n",
      " -10.        ]\n",
      "Optimal Policy at t=5 [0 0 0 0 0 0 0 1 1 1 1]\n",
      "\n",
      "Value Function at t=6 [ -6.596375  -6.596375  -6.597375  -6.605375  -6.632375  -6.696375\n",
      "  -6.7875    -7.        -8.        -9.       -10.      ]\n",
      "Optimal Policy at t=6 [0 0 0 0 0 0 0 1 1 1 1]\n",
      "\n",
      "Value Function at t=7 [ -6.1725  -6.1725  -6.1825  -6.2225  -6.3125  -6.4725  -6.675   -7.\n",
      "  -8.      -9.     -10.    ]\n",
      "Optimal Policy at t=7 [0 0 0 0 0 0 0 1 1 1 1]\n",
      "\n",
      "Value Function at t=8 [ -5.    -5.    -5.1   -5.3   -5.6   -6.    -6.45  -7.    -8.    -9.\n",
      " -10.  ]\n",
      "Optimal Policy at t=8 [0 0 0 0 0 0 0 1 1 1 1]\n",
      "\n",
      "Value Function at t=9 [ -0.  -1.  -2.  -3.  -4.  -5.  -6.  -7.  -8.  -9. -10.]\n",
      "Optimal Policy at t=9 [1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(T):\n",
    "    print(f\"Value Function at t={i}\", V[i])\n",
    "    print(f\"Optimal Policy at t={i}\", pi_star[i])\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
